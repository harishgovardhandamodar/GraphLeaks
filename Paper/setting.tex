\section{Experiment Setup}\label{setup}


\subsection{Datasets}

For the node membership inference and graph reconstruction attack, we consider three standard benchmarking datasets: Pubmed, Citeseer and Cora.

\noindent\textbf{Pubmed.} The Pubmed Diabetes dataset consists of 19717 scientific publications from PubMed database pertaining to diabetes classified into one of three classes. The citation network consists of 44338 links. Each publication in the dataset is described by a TF/IDF weighted word vector from a dictionary which consists of 500 unique words.
We use 60 train samples, 500 validation samples and 1000 test samples.

\noindent\textbf{Citeseer.} The CiteSeer dataset consists of 3312 scientific publications classified into one of six classes.
The citation network consists of 4732 links. Each publication in the dataset is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from the dictionary.
The dictionary consists of 3703 unique words.
The number of training samples is 120, 500 validation samples and 1000 test samples.

\noindent\textbf{Cora.} The Cora dataset consists of 2708 scientific publications classified into one of seven classes.
The citation network consists of 5429 links. Each publication is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from the dictionary.
The dictionary consists of 1433 unique words.
For training 140 samples are used, 300 validation samples and 1000 test samples.

For the attribute inference attack, we consider two social networking datasets with anonymized sensitive attributes: Facebook\footnote{http://snap.stanford.edu/data/ego-Facebook.html} and LastFM\footnote{http://snap.stanford.edu/data/feather-lastfm-social.html}.

\noindent\textbf{Facebook.} The dataset comprises of 4039 nodes representing different user accounts on the social network connected with each other through 88234 edges.
Each user node comprises of different features including the gender, education, hometown etc.
The user information has been anonymized and the interpretation of the features have been obscured, i.e, attributes `Male' or `Female' have been replace with `Gender 1' and `Gender 2'.

\noindent\textbf{LastFM.} The dataset was collected in March 2020 using the public API provided by the social network specifically created for users from Asian countries.
The dataset has 7624 nodes connected together with 27806 edges based on mutual follower relationships.
Each user has attributes such as the music and artists they likes, location etc.


\subsection{Training Methodology}

Graph Embedding algorithms are trained using unsupervised methodology following where the algorithms rely on random walks to generate embedding vectors for each of the nodes.
The resulting embeddings capture the semantic and contextual information of the input graph, for instance,
Specifically, GNNs in the node inference attack case have been trained in an inductive fashion where the model is trained on a subgraph and the evaluation is computed on the remaining nodes.
Hence, the model is evaluated on unseen nodes.
Further, in case of graph reconstruction attack, the training methodology follows inductive approach to clearly separate the graph used for training and testing.


\subsection{Baselines}

\noindent\textbf{Node Inference Attack.} For the inference based on output predictions, we consider the GraphSAGE algorithm as the target GNN model since it can be trained inductively scaling to large datasets.
GraphSAGE extends the operations in GCN to a more generic functions for transformation and aggregating of node features.
While the embedding of graph data in GCN relies on matrix factorization, GraphSAGE uses node features to learn the embedding function.
Instead of learning an embedding vector for each nodes, the algorithm trains the aggregator function to aggregate node features from local neighbourhood as well as from nodes with different number of hops and search depth.
The algorithms supports three aggregation functions: (a) mean, (b) LSTM and (c) pool functions. The algorithms first aggregates the node features from neighbourhood ($k=1$) and concatenates them followed by non-linearity to obtain the features for the node in question.
Formally, $\forall u \in \mathcal{N}(v)\}$, the features are updated as $h^{k}_{N(v)} \leftarrow AGGREGATE_k(\{h^{k-1}_u)$.
This is followed by a weighted concatenation $h^{k}_v \leftarrow \sigma(W^k.CONCATENATE(h^{k-1}_v, h^{k}_{\mathcal{N}(v)}))$.
Here, $k$ represents the different search depths, $u$ and $v$ are nodes, $\mathcal{N}()$ is the function to output neighbourhood nodes and $W$ is the weight matrix for a particular layer learnt during training.
GraphSAGE, at each iteration, aggregates node features from local neighbours across different search depths $k$ to incrementally gain more information from farther nodes in the graph.


On the other hand, for the node i

\noindent\textbf{Graph Reconstruction Attack.} In this attack, we consider the graph embeddings as an output of the convolutional kernel embeddings....


\noindent\textbf{Attribute Inference Attack.} Here, we consider two state of the art unsupervised graph embedding algorithms, namely, Node2Vec and DeepWalk.
Node2Vec..
DeepWalk..

\subsection{Metrics}

The performance of inference attacks, namely, node membership inference and link inference attacks, the inference accuracy is used to estimate the attack success.

\noindent\textbf{Inference Accuracy.} Both the inference attacks are a binary classification problem: node is part of the training data or not (membership inference) and there exists a link between any two nodes or not (Link Inference).
Hence, the accuracy of random guess is 50\% and any higher accuracy indicates a privacy leakage about the model's sensitive training data.

\noindent\textbf{Adversary Advantage.} In order to compute the additional benefit the adversary gets in terms of performing the attack over random guess, we use the adversary advantage as a metric computed as: $ADV = 2*(I_{acc}-0.5)$.
This gives an estimate of the information leakage from the model over and above a completely privacy preserving model (random guess).

For evaluating the performance of graph reconstruction attacks, we use two main metrics: precision and roc score.

\noindent\textbf{Precision.} The ratio of true positives to the sum of true and false positives is given by precision and estimates the percentage of the predicted samples are actually in the target graph data.

\noindent\textbf{ROC-AUC Score.} The ROC curve plots the true positive rate on the y-axis and the false positive rate on the x-axis. The AUC score computes the area under the ROC curve to get how good the model distinguishes between different classes.
For a binary classification problem of graph reconstruction to obtain the binary adjacency matrix, the random guess accuracy is 50\% and any higher accuracy indicates the adversary's advantage in reconstructing the target graph data.

In case of attribute inference attack, we evaluate using the F1 score to balance both the recall and precision.

\noindent\textbf{F1-Score.} This metric computes the harmonic mean between the precision and recall which estimates the percentage of samples in the target graph which are predicted as such.

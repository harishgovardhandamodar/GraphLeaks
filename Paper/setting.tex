\section{Experiment Setup}\label{setup}


\subsection{Datasets}

For the node membership inference and graph reconstruction attack, we consider three standard benchmarking datasets: Pubmed, Citeseer and Cora.

\noindent\textbf{Pubmed.} The Pubmed Diabetes dataset consists of 19717 scientific publications from PubMed database pertaining to diabetes classified into one of three classes. The citation network consists of 44338 links. Each publication in the dataset is described by a TF/IDF weighted word vector from a dictionary which consists of 500 unique words.
We use 60 train samples, 500 validation samples and 1000 test samples.

\noindent\textbf{Citeseer.} The CiteSeer dataset consists of 3312 scientific publications classified into one of six classes.
The citation network consists of 4732 links. Each publication in the dataset is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from the dictionary.
The dictionary consists of 3703 unique words.
The number of training samples is 120, 500 validation samples and 1000 test samples.

\noindent\textbf{Cora.} The Cora dataset consists of 2708 scientific publications classified into one of seven classes.
The citation network consists of 5429 links. Each publication is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from the dictionary.
The dictionary consists of 1433 unique words.
For training 140 samples are used, 300 validation samples and 1000 test samples.

For the attribute inference attack, we consider two social networking datasets with anonymized sensitive attributes: Facebook\footnote{http://snap.stanford.edu/data/ego-Facebook.html} and LastFM\footnote{http://snap.stanford.edu/data/feather-lastfm-social.html}.

\noindent\textbf{Facebook.} The dataset comprises of 4039 nodes representing different user accounts on the social network connected with each other through 88234 edges.
Each user node comprises of different features including the gender, education, hometown etc.
The user information has been anonymized and the interpretation of the features have been obscured, i.e, attributes `Male' or `Female' have been replace with `Gender 1' and `Gender 2'.

\noindent\textbf{LastFM.} The dataset was collected in March 2020 using the public API provided by the social network specifically created for users from Asian countries.
The dataset has 7624 nodes connected together with 27806 edges based on mutual follower relationships.
Each user has attributes such as the music and artists they likes, location etc.


\subsection{Baselines}

For the inference based on output predictions, we consider the \textbf{GraphSAGE} algorithm as the target GNN model since it can be trained inductively scaling to large datasets.
While the embedding of graph data in GCN relies on matrix factorization, GraphSAGE uses node features to learn the embedding function.
GraphSAGE, at each iteration, aggregates node features from local neighbours across different search depths to incrementally gain more information from farther nodes in the graph.
The increase in number of layers results in feature aggregation from nodes in different depths.

For the inference based on intermediate graph embeddings, we


In case of attributer inference attacks, we consider two state of the art unsupervised graph embedding algorithms, namely, Node2Vec and DeepWalk.

\noindent\textbf{Node2Vec.}

\noindent\textbf{DeepWalk.}







\subsection{Metrics}

The performance of inference attacks, namely, node membership inference and link inference attacks, the inference accuracy is used to estimate the attack success.

\noindent\textbf{Inference Accuracy.} Both the inference attacks are a binary classification problem: node is part of the training data or not (membership inference) and there exists a link between any two nodes or not (Link Inference).
Hence, the accuracy of random guess is 50\% and any higher accuracy indicates a privacy leakage about the model's sensitive training data.

\noindent\textbf{Adversary Advantage.} In order to compute the additional benefit the adversary gets in terms of performing the attack over random guess, we use the adversary advantage as a metric computed as: $I_{adv} = 2*(I_{acc}-0.5)$.
This gives an estimate of the information leakage from the model over and above a completely privacy preserving model (random guess).

For evaluating the performance of graph reconstruction attacks, we use two main metrics: precision and roc score.

\noindent\textbf{Precision.} The ratio of true positives to the sum of true and false positives is given by precision and estimates the percentage of the predicted samples are actually in the target graph data.

\noindent\textbf{ROC-AUC Score.} The ROC curve plots the true positive rate on the y-axis and the false positive rate on the x-axis. The AUC score computes the area under the ROC curve to get how good the model distinguishes between different classes.
For a binary classification problem of graph reconstruction to obtain the binary adjacency matrix, the random guess accuracy is 50\% and any higher accuracy indicates the adversary's advantage in reconstructing the target graph data.

In case of attribute inference attack, we evaluate using the F1 score to balance both the recall and precision.

\noindent\textbf{F1-Score.} This metric computes the harmonic mean between the precision and recall which estimates the percentage of samples in the target graph which are predicted as such.
